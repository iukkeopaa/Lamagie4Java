## 如何保证消息队列消费的幂等性，这一块应该还是要结合业务来选择合适的方法，有以下几个方案

消费数据为了单纯的写入数据库，可以先根据主键查询数据是否已经存在，如果已经存在了就没必要插入了。或者直接插入也没问题，因为可以利用主键的唯一性来保证数据不会重复插入，重复插入只会报错，但不会出现脏数据。
消费数据只是为了缓存到redis当中，这种情况就是直接往redis中set value了，天然的幂等性。
针对复杂的业务情况，可以在生产消息的时候给每个消息加一个全局唯一ID，消费者消费消息时根据这个ID去redis当中查询之前是否消费过。如果没有消费过，就进行消费并将这个消息的ID写入到redis当中。如果已经消费过了，就无需再次消费了。  



解决思路是：保证消息的唯一性，就算是多次传输，不要让消息的多次消费带来影响；保证消息的 幂等性；

在消息生产时，MQ内部针对每条生产者发送的消息生成一个inner-msg-id，作为去重和幂等的依据（消息投递失败并重传），避免重复的消息进入队列；
在消息消费时，要求消息体中必须要有一个bizId（对于同一业务全局唯一，如支付ID、订单ID、帖子ID等）作为去重和幂等的依据，避免同一条消息被重复消费


这个问题针对业务场景来答分以下几点（还是要在消费方做数据存储时 手动去重）：

如果消息是做数据库的insert操作，给这个消息做一个唯一主键，那么就算出现重复消费的情况，就会导致主键冲突，避免数据库出现脏数据。
如果消息是做redis的set的操作，不用解决，因为无论set几次结果都是一样的，set操作本来就是幂等操作。
如果以上两种情况还不行，可以准备一个第三方介质,来做消费记录。以redis为例，给消息分配一个全局id，只要消费过该消息，将<id,message>以K-V形式写入redis。那消费者开始消费前，先去redis中查询有没消费记录即可。


全局唯一ID + 消息幂等性存储：

在消息的生产者端，为每条消息生成一个全局唯一的标识符(可以通过UUID或其他机制实现)。
在消费端，维护一个持久化的存储（如数据库或Redis），存储已经被处理的消息。消费者端每次消费消息前，都先检查该消息是否已经被处理过，如果消息已经被处理过，则忽略他；否则处理消息对应的逻辑，并把当前处理成功的消息存储。
2、重试机制和死信队列：

RabbitMQ提供了重试机制，当消费失败时，根据策略重新发送消息或进行其他处理。
当消息在队列中无法被正常消费（例如达到最大重试次数）时，可以将其路由到死信队列。这样，可以单独处理这些无法消费的消息，避免它们被反复发送和重复消费。
3、合理设计消费者数量：

根据系统的负载情况和消费者的处理能力，合理调整消费者的数量。如果消费者数量过多，可能导致消息被多个消费者同时处理，增加重复消费的风险；如果消费者数量过少，可能导致消息处理速度过慢，造成消息堆积。因此，需要根据实际情况进行动态调整。
4、设置合适的过期时间：
RabbitMQ允许为消息设置过期时间，过期后未被消费的消息将被自动删除，从而减少长时间滞留在队列中导致的重复消费风险。
5、使用RabbitMQ的消息属性：
RabbitMQ提供了消息属性，如messageId或correlationId，这些可以作为消息的唯一标识符。消费者可以利用这些属性进行消息去重或跟踪。   


其实还是得结合业务来思考，我这里给几个思路：

比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，
update 一下好吧。

比如你是写 Redis，那没问题了，反正每次都是 set，天然幂等性。

比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候，
里面加一个全局唯一的 id，类似订单 id 之类的东西，然后你这里消费到了之后，先根据这
个 id 去比如 Redis 里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个 id 写
Redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。

比如基于数据库的唯一键来保证重复数据不会重复插入多条。因为有唯一键约束了，重复
数据插入只会报错，不会导致数据库中出现脏数据。

## 消息大量积压怎么解决？

消息的积压来自于两方面：要么发送快了，要么消费变慢了。

单位时间发送的消息增多，比如赶上大促或者抢购，短时间内不太可能优化消费端的代码来提升消费性能，唯一的办法是通过扩容消费端的实例数来提升总体的消费能力。严重影响 QM 甚至整个系统时，可以考虑临时启用多个消费者，并发接受消息，持久化之后再单独处理，或者直接丢弃消息，回头让生产者重新生产。

如果短时间内没有服务器资源扩容，没办法的办法是将系统降级，通过关闭某些不重要的业务，减少发送的数据量，最低限度让系统还能正常运转，服务重要业务。

监控发现，产生和消费消息的速度没什么变化，出现消息积压的情况，检查是有消费失败反复消费的情况。

监控发现，消费消息的速度变慢，检查消费实例，日志中是否有大量消费错误、消费线程是否死锁、是否卡在某些资源上。


## 1、上千万条消息在mq中积压了几个小时还没解决：

1.  先修复consumer的问题，确保其恢复消费速度，然后将现有consumer都停掉；

2.  新建?个topic，partition是原来的10倍，临时建?好原先10倍或者20倍的queue数量；

3.  然后写?个临时的分发数据的consumer程序，这个程序部署上去消费积压的数据；消费之后不做耗时的处理，直接均匀轮询写?临时建?好的10倍数量的queue；

4.  接着临时征?10倍的机器来部署consumer，每?批consumer消费?个临时queue的数据；

5.  这种做法相当于是临时将queue资源和consumer资源扩?10倍，以正常的10倍速度来消费数据；

6.  等快速消费完积压数据之后，得恢复原先部署架构，重新?原先的consumer机器来消费消息。

**总结：**

1.  修复并停掉consumer；

2.  新建?个topic，partition是原来的10倍，建?临时queue，数量是原来的10倍或20倍；

3.  写临时consumer程序，临时征?10倍的机器去消费数据；

4.  消费完成之后，恢复原先consumer；
## 8、消息基于什么传输？

由于TCP连接的创建和销毁开销较?，且并发数受系统资源限制，会造成性能瓶颈。

RabbitMQ使?信道的?式来传输数据。信道是建?在真实的TCP连接内的虚拟连接，且每条

TCP连接上的信道数量没有限制。

1.  RabbitMQ采?类似NIO（Non-blocking I/O）做法，选择TCP连接复?，不仅可以减少性能开销，同时也便于管理。

2.  每个线程把持?个信道，所以信道服?了Connection的TCP连接。同时RabbitMQ可以确保每个线程的私密性，就像拥有独立的连接一样。


## 14、MQ如何选型？


1.  中?型公司?选RabbitMQ：管理界?简单，?并发。

2.  ?型公司可以选择RocketMQ：更?并发，可对rocketmq进?定制化开发。

3.  ?志采集功能，?选kafka，专为?数据准备。

## 15、如何保证消息队列?可?？

**1\. 集群：**

![别找了，Java面试还愁被问RabbitMQ？看完这22道问题解析就够了！](https://upload-images.jianshu.io/upload_images/11474088-db2bf3f27dfbf0ec?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

*   集群可以扩展消息通信的吞吐量，但是不会备份消息，备份消息要通过镜像队列的?式解决。

*   队列存储在单个节点、交换器存储在所有节点。

**2\. 镜像队列：**将需要消费的队列变为镜像队列，存在于多个节点，这样就可以实现RabbitMQ

的HA?可?性。作?就是消息实体会主动在镜像节点之间实现同步，?不是像普通模式那样，

在consumer消费数据时临时读取。缺点就是，集群内部的同步通讯会占??量的?络带宽。

![别找了，Java面试还愁被问RabbitMQ？看完这22道问题解析就够了！](https://upload-images.jianshu.io/upload_images/11474088-94a4a07bedf7b68b?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

## Kafka、ActiveMQ、RabbitMQ、RocketMQ 有什么优缺点？

综上，各种对比之后，有如下建议：

一般的业务系统要引入 MQ，最早大家都用 ActiveMQ，但是现在确实大家用的不多了，没经过
大规模吞吐量场景的验证，社区也不是很活跃，所以大家还是算了吧，我个人不推荐用这个
了；

后来大家开始用 RabbitMQ，但是确实 erlang 语言阻止了大量的 Java 工程师去深入研究和掌控
它，对公司而言，几乎处于不可控的状态，但是确实人家是开源的，比较稳定的支持，活跃度
也高；

不过现在确实越来越多的公司会去用 RocketMQ，确实很不错，毕竟是阿里出品，但社区可能有
突然黄掉的风险（目前 RocketMQ 已捐给 Apache，但 GitHub 上的活跃度其实不算高）对自己
公司技术实力有绝对自信的，推荐用 RocketMQ，否则回去老老实实用 RabbitMQ 吧，人家有活
跃的开源社区，绝对不会黄。

所以中小型公司，技术实力较为一般，技术挑战不是特别高，用 RabbitMQ 是不错的选择；大
型公司，基础架构研发实力较强，用 RocketMQ 是很好的选择。

如果是大数据领域的实时计算、日志采集等场景，用 Kafka 是业内标准的，绝对没问题，社区
活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范。

## mq 中的消息过期失效了

假设你用的是 RabbitMQ，RabbtiMQ 是可以设置过期时间的，也就是 TTL。如果消息在 queue
中积压超过一定的时间就会被 RabbitMQ 给清理掉，这个数据就没了。那这就是第二个坑了。
这就不是说数据会大量积压在 mq 里，而是大量的数据会直接搞丢。

这个情况下，就不是说要增加 consumer 消费积压的消息，因为实际上没啥积压，而是丢了大
量的消息。我们可以采取一个方案，就是批量重导，这个我们之前线上也有类似的场景干过。
就是大量积压的时候，我们当时就直接丢弃数据了，然后等过了高峰期以后，比如大家一起喝
咖啡熬夜到晚上12点以后，用户都睡觉了。这个时候我们就开始写程序，将丢失的那批数据，
写个临时程序，一点一点的查出来，然后重新灌入 mq 里面去，把白天丢的数据给他补回来。
也只能是这样了。

假设 1 万个订单积压在 mq 里面，没有处理，其中 1000 个订单都丢了，你只能手动写程序把那
1000 个订单给查出来，手动发到 mq 里去再补一次。


## 、如何解决消息解压问题
1. 消息过多，消费者消费速度太慢。
- 多个消费者并发消费
- 多线程并发消费
- 设置消息存活时间(TTL) Time To Live
- 设置队列中存储消息的界限(Lim) limit
-
2. 消费者消费失败，消息还在业务队列中。
- 再重试一次，如果还不行，扔到死信队列，避免队列阻塞。