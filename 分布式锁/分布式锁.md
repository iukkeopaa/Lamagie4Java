##  分布式锁的实现方案。

基于数据库实现分布式锁基于数据库表（锁表，很少使用）乐观锁(基于版本号)悲观锁(基于排它锁)


基于 redis 实现分布式锁: 单个Redis实例：setnx(key,当前时间+过期时间) + LuaRedis集群模式：Redlock基于 

zookeeper实现分布式锁临时有序节点来实现的分布式锁,

Curator基于 Consul 实现分布式锁

## 基于数据库表（锁表，很少使用）

最简单的方式可能就是直接创建一张锁表，然后通过操作该表中的数据来实现了。当我们想要获得锁的时候，就可以在该表中增加一条记录，想要释放锁的时候就删除这条记录。

基于悲观锁悲观锁实现思路？
在对任意记录进行修改前，先尝试为该记录加上排他锁（exclusive locking）。如果加锁失败，说明该记录正在被修改，那么当前查询可能要等待或者抛出异常。 具体响应方式由开发者根据实际需要决定。如果成功加锁，那么就可以对记录做修改，事务完成后就会解锁了。其间如果有其他对该记录做修改或加排他锁的操作，都会等待我们解锁或直接抛出异常。

要使用悲观锁，我们必须关闭mysql数据库的自动提交属性，因为MySQL默认使用autocommit模式，也就是说，当你执行一个更新操作后，MySQL会立刻将结果进行提交。set autocommit=0;//0.开始事务

begin;/begin work;/start transaction; (三者选一就可以)
//1.查询出商品信息
select status from t_goods where id=1 for update;
//2.根据商品信息生成订单
insert into t_orders (id,goods_id) values (null,1);
//3.修改商品status为2
update t_goods set status=2;
//4.提交事务
commit;/commit work;

上面的查询语句中，我们使用了select…for update的方式，这样就通过开启排他锁的方式实现了悲观锁。此时在t_goods表中，id为1的 那条数据就被我们锁定了，其它的事务必须等本次事务提交之后才能执行。这样我们可以保证当前的数据不会被其它事务修改。上面我们提到，使用select…for update会把数据给锁住，不过我们需要注意一些锁的级别，MySQL InnoDB默认行级锁。行级锁都是基于索引的，如果一条SQL语句用不到索引是不会使用行级锁的，会使用表级锁把整张表锁住，这点需要注意。



基于乐观锁乐观并发控制（又名“乐观锁”，Optimistic Concurrency Control，缩写“OCC”）是一种并发控制的方法。它假设多用户并发的事务在处理时不会彼此互相影响，各事务能够在不产生锁的情况下处理各自影响的那部分数据。在提交数据更新之前，每个事务会先检查在该事务读取数据后，有没有其他事务又修改了该数据。如果其他事务有更新的话，正在提交的事务会进行回滚。


## 基于redis如何实现分布式锁？有什么缺陷？

set NX PX + Lua
、




## 分布式锁必备特征


第一个特征，**高性能**。这个比较好理解，分布式锁的性能很低的话，那会严重影响我们的主业务逻辑。比如我们设计一款秒杀系统，秒杀系统的关键是什么？是追求高 QPS 以及不能超卖，我们假设用分布式锁来防止超卖的情况，那即便我们的秒杀代码写得很 nice，性能达到了极致，但是每次上锁和解锁都花了几百毫秒，这能忍吗？肯定不能！所以分布式锁一定要高性能。

第二个特征，**可重入**。对 Java 的基础锁有了解的同学肯定一下就知道什么意思了，就是比如 A 线程对 test() 方法进行了上锁，test() 方法内部又调用了一个 abc() 方法，这个 abc() 方法也有锁，那会出现什么情况呢？死锁了！因为 test方法() 请求 abc() 方法的时候一直阻塞着，却又无法释放，伪代码如下：

```java
public synchronized void test() {
    // 阻塞卡死了
    abc();
}

public synchronized void abc() {}
```

所以这时候就需要可重入，**可重入的条件就是持有锁的线程是当前请求的线程。** 比如上面例子中，test() 方法和 abc() 方法是同步调用的，明显是一个线程，这时候就要可以正常请求，而不是阻塞等待卡死。需要注意的点就是：**重入几次就要释放几次。**

第三个特征，**防死锁**。上面刚讲解的，如果锁是不可重入的，那很可能就导致死锁了。还有一种情况就是客户端 1 加锁了，还没来得及释放，服务宕机了，那这把锁怎么释放？不释放的话其他客户端永远执行不了这个方法，当机器恢复后客户端 1 也无法执行，这也是一种死锁的表现，具体用什么手段去防止这种情况的发生，后面的篇幅会详细分析。

第四个特征，**互斥性**。互斥性用一句话来描述就是：**不允许多个客户端同时执行一段代码。** 比如，客户端 A 在执行 method1()，这时候客户端 B 进来了，也在执行 method1()，客户端 A 和客户端 B 同时执行，这就不具备互斥性。正常互斥的逻辑应该是客户端 A 执行 method1() 就相当于给大门上了一把锁，当其他客户端再来的时候发现大门是锁着的，没有钥匙，只能等待。只有当客户端 A 释放锁（打开大门后），其他客户端才能进去抢锁（钥匙）。

关于这四个核心特征我们已经知道其含义了，那该如何实现这四个特征呢？下面我们一个一个“攻破”。

先来看**高性能**，这个没什么好说的，举个最简单的例子：你把锁存在磁盘上，每次从磁盘上拿数据，那肯定性能较低；但是你把锁存到内存中，每次从内存中取数据，那肯定效率远大于磁盘的方式。我们使用分布式锁直接采取业界成熟的开源框架，比如 Redis 和 ZooKeeper，所以性能问题无须我们考虑，我们只需要知道分布式锁肯定要高性能，否则拖慢了业务系统的 rt 那不是浪费感情吗？

再来看**可重入和互斥性**。锁重入怎么设计？也很简单，为每个线程单独记录下重入次数，比如线程 1 重入 2 次，那就是`thread1:2`。核心逻辑就是：请求进来后判断有没有锁，没有锁就加锁，有锁就继续判断持有锁的线程是不是当前请求线程，是的话就是锁重入，直接给重入次数 +1 即可。那如果有锁，且持有锁的线程不是自己怎么办？那肯定**要互斥**的，直接调`wait()`方法阻塞等待即可。

最后看看如何**防死锁**。造成死锁的原因就是服务意外宕机导致锁永远得不到释放，那我们有办法保证服务 100% 不意外宕机吗？我们没办法保证！那就需要考虑宕机后该怎么自动释放锁了，我们可以给每把锁添加过期时间，这样假设服务意外宕机了，但是锁等待一段时间超时了就会自动释放了，避免了死锁的发生。


## 分布式锁应用场景

* **防止缓存击穿**。缓存击穿是什么？比如某购物平台创建了一个秒杀 iPhone 13 的活动，这时候流量肯定不能直接打到数据库，因为数据库扛不住，我们需要缓存起来，假设放到了 Redis，那如果 Redis 里 iPhone 13 这个 key 失效了，这时候秒杀的流量不就都打到数据库了吗？所以这时候可以在查数据库的时候加一个分布式锁，查出来后再把数据缓存到 Redis，这样就能保证大流量请求进来的时候，即便 Redis 失效了也只会有一个请求同时打到数据库中。这就是缓存击穿以及用分布式锁来解决缓存击穿的实现思路。

* **保证接口幂等性**。举个最简单的例子：表单重复提交，点击提交后还没处理完，又点击了一次提交按钮，这时候就相当于提交了两份。分布式锁也可以解决此场景，提交接口添加分布式锁，第一次提交的时候会锁住，然后第二次提交发现有锁，就不会执行业务逻辑了。

* **任务调度**。比如要写个定时器，定时统计数据发邮件，我们部署了五台机器，如果没用其他分布式调度框架的话，那岂不是五台机器都在执行定时任务，每天收到五封完全相同的邮件？其实，此场景也可以用分布式锁来保证集群部署的时候只有一台在工作，其他机器执行的时候发现有锁就不再执行了。

* **秒杀减库存等类似业务防止超卖的情况**（这个前面我们已经举过例子了，这里就不再赘述了）。

## 在上一讲中，我们主要讲解了分布式锁是什么以及为什么需要分布式锁这两个话题，也提了一下实现分布式锁的核心设计方案以及目前有哪几种成熟的方案，但是每一种方案具体如何实现我们还不知道，此篇开始以及以后篇幅的核心主题就是具体的实现原理和细节了。

此篇先从最简单的开始讲起：MySQL如何实现一把分布式锁？本篇的讲解方式是会先讲明白原理，然后再讲具体的代码实现，最后来总结下MySQL作为分布式锁的优缺点，只有讲明白了原理才能更好的掌握代码实现，就好比没有需求（需求=原理），你怎么写代码？所以进入正题，我们看下MySQL作为分布式锁的实现原理是什么？

# 一、实现原理

一把锁应该具备哪些特点？最核心最基本的就是：**互斥性。**

什么是互斥性？上一篇刚讲过，这次在复习下。互斥性用一句话来描述的话就是：**不允许多个客户端同时执行一段代码。** 比如客户端A在执行method1(资源A)，这时候客户端B进来了，也在执行method1(资源A)，客户端A和客户端B同时执行。这就不具备互斥性，正常互斥的逻辑应该是客户端A执行method1(资源A)就相当于给资源A这个大门上了一把锁，当其他客户端再来的时候发现大门是锁着的，没有钥匙，只能等待。只有当客户端A释放锁（打开大门）后，其他客户端才能进去抢锁（钥匙）。

现在我们知道了什么是互斥性，那MySQL该如何实现这一特征呢？表该如何设计呢？

其实也很简单：**利用唯一索引**来实现，只要抢占锁了就插入一条记录，多客户端抢锁会互斥，互斥体现在插入重复数据会报唯一key的异常。简单总结下流程：

* 客户端1先来加锁，这时候没有其他客户端持有锁，所以加锁成功，也就是在表里insert一条数据成功。
* 这时候客户端2也来加锁，发现客户端1正在持有锁（表里有数据），肯定是不能加锁成功的，会返回key重复的异常（或者提前select一下看看有没有数据，有数据就代表有锁），这时候就进行重试加锁。

* 持有锁的线程执行完逻辑后需要释放锁，释放锁就直接把数据表里的记录删除就好了。这样其他客户端就能正常抢到锁了。

![lock.png](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/be89891c4a494efbbe838f18440b8e94~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.image#?w=1220&h=464&s=39282&e=png&b=ffffff)

大概流程知道了，也很简单。但是你是不是有很多疑问？比如如下：

* 分布式锁的表怎么设计？唯一key怎么确定是哪个字段？
* 抢锁失败后要重试，怎么重试？
* 释放锁就是删除记录，那如何安全的释放锁？

下面一个个分析这四个问题。先来看第一个：**分布式锁的表怎么设计？唯一key怎么确定是哪个字段？**

## 1\. 表设计和唯一key

我们首先能想到的一种方式是：每个需要分布式锁的业务都单独建立一张表，比如订单业务需要分布式锁，那就搞个order\_lock表，核心字段：order\_id和user\_id。order\_id是唯一索引，不允许重复，如果有order\_id那就代表加锁状态，其他客户端来后如果并发insert同一个订单了，那肯定报唯一key冲突错误，这样就可以确保只有一个客户端持有锁了，表设计如下：

```sql
DROP TABLE IF EXISTS `order_lock`;
CREATE TABLE `order_lock` (
 ?`order_id` int NOT NULL,
 ?`user_id` int DEFAULT NULL,
 ?PRIMARY KEY (`order_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
```

但是他有什么弊端？**不通用。** 每个需要分布式锁的业务都要单独创建一个lock表来存储锁状态，对于使用者来讲很不友好，那怎么设计成一张通用的分布式锁表呢？

我们想想都需要哪些字段？首先并发线程不安全是作用在同一个方法上的不同线程，对不对？那不就有了唯一字段：方法名了吗？但是不同项目的方法名又可能相同，比如都叫save，那怎么办？这不又多了一个项目id或者项目名称了吗？所以方法名和项目名是个组合唯一索引。SQL如下：

```sql
DROP TABLE IF EXISTS `common_lock`;
CREATE TABLE `common_lock` (
 ?`id` int NOT NULL,
 ?`method_name` varchar(30) DEFAULT NULL,
 ?`project_name` varchar(30) DEFAULT NULL,
 ?PRIMARY KEY (`id`),
 ?UNIQUE KEY `lock_key` (`project_name`,`method_name`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
```

这样好像确实解决了我们的问题，但是存在问题，因为锁的不是方法，而是资源，比如不同线程都操作method1，但是参数（资源）不同，那是无所谓的，所以我们还差个资源ID。SQL如下：

```sql
DROP TABLE IF EXISTS `common_lock`;
CREATE TABLE `common_lock` (
 ?`id` int NOT NULL,
  `resource_id` int NOT NULL,
 ?`method_name` varchar(30) DEFAULT NULL,
 ?`project_name` varchar(30) DEFAULT NULL,
 ?PRIMARY KEY (`id`),
 ?UNIQUE KEY `lock_key` (`project_name`,`method_name`,`resource_id`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
```

目前为止基本功能实现了，但是不完善，为什么？因为我们想要的效果是支持重入，那怎么做可重入？可重入的关键在于需要一个字段存储重入次数，所以我们还少了个entry\_count字段，加上这个就可以了吗？他是哪个线程重入的？我们并不知道。所以还需要一个thread\_id字段。但是你想想这样就可以了么？现在都集群部署，不同机器的线程id是可以一样的，所以是不是还需要机器ip？所以一个相对完善的SQL如下：

```sql
DROP TABLE IF EXISTS `common_lock`;
CREATE TABLE `common_lock` (
 ?`id` int NOT NULL,
  `resource_id` int NOT NULL,
 ?`method_name` varchar(30) NOT NULL,
 ?`project_name` varchar(30) NOT NULL,
 ?`thread_id` int NOT NULL,
 ?`entry_count` int NOT NULL,
 ?`host_ip` varchar(30) NOT NULL,
 ?PRIMARY KEY (`id`),
 ?UNIQUE KEY `lock_key` (`project_name`,`method_name`,`resource_id`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
```

还有没有可优化的空间？

我们第一感觉好像挺完美，但是你想想我们只想知道一个唯一key和这个key的重入次数，结果搞出来这么多字段，这样好吗？我个人认为不怎么好，还可以继续优化：将`resource_id`、`method_name`、`project_name`这三个字段设计成一个key，比如提供一个方法就叫getKey：

```scss
// 也可以考虑加密一下，缩短长度。但是建议可解密，这样可以反推出来是哪个项目哪个方法加的锁。
public String getKey() {
 ? ?return 
 ? ? ? ?new StringBuilder()
 ? ? ?  .append(getProjectName())
 ? ? ?  .append("_")
 ? ? ?  .append(getMethodName())
 ? ? ?  .append("_")
        .append(getResourceId())
 ? ? ?  .toString();
}
```

然后SQL就变成了最终这个样子：

```sql
DROP TABLE IF EXISTS `common_lock`;
CREATE TABLE `common_lock` (
 ?`id` int NOT NULL,
 ?`lock_key` varchar(100) NOT NULL,
 ?`thread_id` int NOT NULL,
 ?`entry_count` int NOT NULL,
 ?`host_ip` varchar(30) NOT NULL,
 ?PRIMARY KEY (`id`),
 ?UNIQUE KEY `lock_key` (`lock_key`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
```

我们考虑到了重入的情况，那重入的逻辑是怎样的呢？

**很简单，判断有没有锁，有锁，再继续判断是不是自己加的锁，是自己加的锁，那就update entry\_count字段+1就完事了。**

那如果不是自己加的锁呢？这时候就是锁已经被其他人持有了，我又来加锁，加锁失败了，我该怎么办？重试，那重试策略有哪些呢？

## 2\. 重试策略

常规的两种重试策略就是：**死循环一直重试和重试一定次数或者重试一定的时间后还是加锁失败的话就退出。**

看下一直重试策略的伪代码：

```kotlin
if (加锁失败) {
 ? ?while(true) {
 ? ? ? ?// 重试加锁
 ? ? ? ?if (重试成功) {
 ? ? ? ? ? ?return true;
 ? ? ?  }
        // 休息一定时间
 ?  }
}
```

那重试一定次数或者重试一定时间后还是失败就退出的代码该怎么写呢？这就太简单了，就是基于上面代码加一个重试次数字段，每次重试+1，判断达到次数后还没成功就`return false`。重试一定时间后退出和重试一定次数后退出的思路是一样的，记录下重试前的时间，然后每次重试都对比时间，看看是不是超出了用户自定义的时间，超出了就`return false`代表加锁失败。

现在加锁的核心逻辑基本已经搞定了，那方法执行完后怎么释放锁呢？

## 3\. 释放锁

直接删除这个key可行吗？肯定**不可行**！因为有锁重入的情况，比如我重入了2次，释放了1次锁，你就直接给我把锁删除了，那不就出问题了吗？所以需要先判断下锁重入次数，如果锁重入次数大于1，那就将其减1，如果等于1，那就直接delete这条数据。

锁释放后，其他客户端重试的时候就会进行加锁成功了。

![unlock.png](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/448f1733de8849fabf43bc4490eca9cf~tplv-k3u1fbpfcp-jj-mark:1600:0:0:0:q75.image#?w=1354&h=670&s=68233&e=png&b=ffffff) 好了，到目前为止我们分析了MySQL作为分布式锁该如何设计、如何加锁、如何重试以及如何解锁。但是还有一个致命的问题可能发生，那就是**死锁**。

想一个场景：假设加锁成功，还没来得及释放系统就宕机了，当他再次恢复的时候发现锁还在，永远无法上锁成功，导致了死锁。这种情况怎么办？证明我们上面的设计还不是很严谨，存在巨大的bug！那该如何防止死锁呢？

## 4\. 防死锁

防死锁的处理方式也很简单，我们**搞个定时器定时检查那些由于意外宕机或者其他外界原因导致锁一直没释放的那些数据来防止死锁。**

那我怎么知道哪些锁数据是由于宕机或者其他原因导致的一直无法释放呢？

**可以记录下加锁时间，然后定时器定时去扫描超出n秒（可以在加锁的时候让用户自定义传递时间参数）后还未释放锁的数据，将其删除释放。**

但是这样又存在一个巨大的问题：如果我们的方法很耗时，就是没执行完，但是定时任务扫描的时候却认为我的锁超时了，给我释放了，这时候其他客户端又能成功上锁了，这不是出问题了吗？所以MySQL实现分布式锁简直太不可靠了，那这种能解决吗？肯定是可以解决的，解决方案就是单独起个线程进行定时续期，具体的细节我们在介绍Redis实现分布式锁的时候详细介绍，也就是大名鼎鼎的watchDog机制。

现在MySQL实现分布式锁的细节和原理以及可能出现的问题全部分析完毕了，最后在花点时间总结下他的优缺点。

# 二、优缺点

**优点：**

* 实现方式很简单，搞一张表，两个字段：唯一key和重入次数，然后操作的时候只涉及单表insert和delete以及重入的时候update重入次数+1即可。
* 不额外引入其他中间件，比如Redis、Zookeeper、Etcd等。直接MySQL就搞定了，如果用的其他数据库（比如Oracle等），也是一样的思路和逻辑。

**缺点：**

* 性能很低、支持的并发不高。因为每次加锁、解锁、重入的时候都要额外操作一次MySQL。最简单的场景加锁解锁不考虑重入，那还需要额外与MySQL交互两次呢。
* 线程不安全，虽然有办法解决死锁的问题，但是无法保证绝对的安全。也就是上面说的：方法没执行完，但是超出了设定时间，这时候定时器扫描的时候替我们释放锁了，其他客户端就又能加锁了，这时候其他客户端和我当前客户端同时拥有一把锁。
* 强制依赖MySQL，所以MySQL不能出现单点故障的问题，可搞两个MySQL数据库做同步。但是为了分布式锁搞n台MySQL有点不合适。
* 支持的锁种类有限，我们实现的是非公平锁，要想实现公平锁还需要搞个表来模拟队列，先来后到，多一张表就多一次与MySQL的交互，即使能做，但是如果实现读写锁呢？岂不是更麻烦了。

# 三、总结

本篇文章介绍的是基于MySQL实现的分布式锁的核心原理以及具体伪代码实现，可以发现MySQL实现分布式锁太简单了，核心原理可以总结为一句话：**基于MySQL的唯一索引在insert的时候会出现重复key的错误来实现。**

我们也分析了他的利弊，**MySQL实现性能上肯定是不如Redis和Zookeeper的**。所以我个人是不建议使用MySQL作为分布式锁来用的，如果项目对性能要求不高，也没有很高的并发量，但是有分布式锁的需求，还不想引入其他中间件（比如Redis、Zookeeper），那可以考虑采取MySQL来实现。

此篇很关键，一定要反复看，一定要掌握核心的设计思想，不管是Redis做分布式锁还是Zookeeper做分布式锁，他们的核心思想都大同小异，说简单点都是确定如何存储、如何确定唯一key、如何做到可重入和如何释放锁。源码不重要，掌握核心才是关键！   
